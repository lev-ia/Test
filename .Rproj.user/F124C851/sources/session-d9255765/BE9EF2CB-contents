---
title: "Trial 1"
author: "Levia"
output: 
  html_document:
    toc: true
    theme: united
date: "2023-04-03"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

[Back to README](/Test) | [Next R Code](/Test/Trial-2)

This is a trial for R Markdown 
Today is 4 April 2023

Triple ' followed by {r} will start an r block
e.g. Loading library  
all library used in this project
``` {r, warning = FALSE, message = FALSE}
library(actuar)
library(cluster)
library(dplyr)
library(EnvStats)
library(factoextra)
library(fitdistrplus)
library(ggplot2)
library(goftest)
library(kableExtra)
library(MASS)
library(randomForest)
library(readr)
library(readxl)
library(rmarkdown)
library(stringi)
library(stringr)
library(tibble)
library(tidyr)
library(tidyverse)
```

e.g. loading data
``` {r}
load(file = "census.RData")
load(file = "emissions.RData")
load(file = "hazards.RData")
load(file = "inflation.RData")
load(file = "rates.RData")
```

e.g. glimpse
```{r}
glimpse(inflation)
```

### OK LOADING DONE
note to self:  
original data was csv which cant be read somehow here,  
so do read.csv of each files according to each form.  
then do save each files to .RData form. 
then load it to the rmd space.  
[RMarkdown Cheat Sheet](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf)
  
## NEXT seperate the EDA, Fitting, and Simulation




# 1. Prelim_Clustering ####
Initially we try to cluster the hazards based on it's event and the damages it brought.  
```{r, warning=FALSE, message=FALSE}
# Setting up the environment, load the necessary packages
library(cluster)
library(dplyr)
library(factoextra)
library(ggplot2)
library(readr)
library(stringi)
library(tidyverse)
```

**Load the data**
```{r, eval=TRUE} 
load(file = "hazards.RData")
glimpse(hazards)
```
**Data Cleaning**  

* Change the `Region` column from integer to character  
  
* Filter event that has impact, identified from:  
  
  + Property damage > 0 or  
    
  + Injuries > 0 or  
    
  + Fatalities > 0  
```{r}
hazards$Region = as.character(hazards$Region)
hazards = hazards %>%
  filter(hazards$Property.Damage > 0 | hazards$Injuries > 0 | hazards$Fatalities > 0)
glimpse(hazards)
head(hazards, 5)
```
_Additional Steps_
```{r}
# combine anything with flooding & costal 
# combine storm/hail/wind/lightening as they represent extreme weather conditions cause meteorological hazards.
for (i in 1:nrow(hazards)) {
  if (stri_detect_fixed(hazards[i,"Hazard.Event"], "Hurricane") == TRUE ) {
    hazards[i,"Hazard.Event"] = "Hurricane" 
  } else if ( stri_detect_fixed(hazards[i,"Hazard.Event"], "Coastal") == TRUE ) {
    hazards[i,"Hazard.Event"] = "Coastal" 
  } else if (stri_detect_fixed((hazards[i,"Hazard.Event"]), "Flooding") == TRUE){
    hazards[i,"Hazard.Event"] = "Flooding" 
  } else if (stri_detect_fixed((hazards[i,"Hazard.Event"]), "Storm") == TRUE || 
             stri_detect_fixed((hazards[i,"Hazard.Event"]), "Hail") == TRUE ||
             stri_detect_fixed((hazards[i,"Hazard.Event"]), "Wind") == TRUE ||
             stri_detect_fixed((hazards[i,"Hazard.Event"]), "Lightning") == TRUE  ||
             stri_detect_fixed((hazards[i,"Hazard.Event"]), "Winter Weather") == TRUE){
    hazards[i,"Hazard.Event"] = "Severe Weather" 
  } else if (stri_detect_fixed((hazards[i,"Hazard.Event"]), "Drought") == TRUE || 
             stri_detect_fixed((hazards[i,"Hazard.Event"]), "Heat") == TRUE) {
             hazards[i,"Hazard.Event"] = "Drought/Heat" 
  }
}

# removed year and region columns to evaluate the historical event's clustering regardless of time and place
hazards.agg <- hazards %>%
  dplyr::select(-c(Year, Region))

hazards.agg2 =  hazards.agg %>% 
  group_by(Hazard.Event) %>% 
  summarize(Property.Damage.agg = sum(Property.Damage), 
         Injuries.agg = sum(Injuries),Fatalities.agg = sum(Fatalities),
         Freq = n()) %>%
  mutate(Property.Damage.avg = Property.Damage.agg/Freq , 
         Injuries.avg = Injuries.agg/Freq,Fatalities.avg =Fatalities.agg/Freq) %>%
  remove_rownames %>% column_to_rownames(var="Hazard.Event")

# drop fog/landslide due to its scarcity 
hazards.agg2 = hazards.agg2[!(row.names(hazards.agg2) %in% c("Fog","Landslide")),]
```
**Event's clustering via kmeans**
```{r}
df = scale(hazards.agg2)
k4 <- kmeans(df[,c("Property.Damage.avg", "Fatalities.avg","Injuries.avg","Freq")], centers = 3)

distance <- get_dist(df)
```
```{r, echo=FALSE}
fviz_cluster(k4, df, geom = "text")
```





# 2. Goodness_of_Fit_Tests ####
```{r, warning=FALSE, message=FALSE}
# Setting up the environment, load the necessary packages
library(actuar)
library(dplyr)
library(EnvStats)
library(fitdistrplus)
library(kableExtra)
library(knitr)
library(ggplot2)
library(goftest)
library(MASS)
library(tidyr)
```
**Setting up and data preparation**
```{r, warning=FALSE}
options(scipen=999)
set.seed(123)

# load data
load(file = "census.RData")
load(file = "hazards.RData")

# filtering non-impacting hazards
hazards <- hazards %>% arrange(Year) %>% filter(Property.Damage != 0)
# convert census type such that it could be read
census[,] <- sapply(census[, ], as.numeric) 
str(census)

# create clustering
clusters <- hazards %>%
  mutate(Hazard.Event = 
           recode(Hazard.Event, 
                  "Hail/ Wind" = "Severe Weather",
                  "Winter Weather"= "Severe Weather",
                  "Wind" = "Severe Weather", 
                  "Hail/ Severe Storm/Thunder Storm" = "Severe Weather",
                  "Severe Storm/Thunder Storm" = "Severe Weather", 
                  "Hail" = "Severe Weather", 
                  "Severe Storm/Thunder Storm/ Wind" = "Severe Weather",
                  "Lightning" = "Severe Weather",
                  "Lightning/ Wind" = "Severe Weather",
                  "Tornado"  = "Tornado",
                  "Coastal/ Wind" = "Severe Weather",
                  "Hurricane/Tropical Storm" = "Hurricane",
                  "Flooding" = "Flooding",
                  "Hail/ Lightning/ Wind" = "Severe Weather",
                  "Hail/ Severe Storm/Thunder Storm/ Wind" = "Severe Weather",
                  "Lightning/ Severe Storm/Thunder Storm" = "Severe Weather",
                  "Wildfire" = "Wildfire",
                  "Hail/ Lightning/ Severe Storm/Thunder Storm" = "Severe Weather",
                  "Hail/ Lightning/ Severe Storm/Thunder Storm/ Wind" = "Severe Weather",
                  "Tornado/ Wind" = "Tornado",
                  "Hail/ Tornado/ Wind" = "Tornado",
                  "Lightning/ Severe Storm/Thunder Storm/ Wind" = "Severe Weather",
                  "Severe Storm/Thunder Storm/ Winter Weather" = "Severe Weather",
                  "Wind/ Winter Weather" = "Severe Weather",
                  "Coastal/ Hurricane/Tropical Storm/ Wind" = "Hurricane",
                  "Severe Storm/Thunder Storm/ Wind/ Winter Weather" = "Severe Weather",
                  "Flooding/ Severe Storm/Thunder Storm" = "Flooding",
                  "Coastal" = "Coastal",
                  "Hail/ Lightning" = "Severe Weather",
                  "Flooding/ Lightning/ Severe Storm/Thunder Storm" = "Flooding",
                  "Heat" = "Drought/ Heat",
                  "Drought/ Heat" = "Drought/ Heat",
                  "Flooding/ Severe Storm/Thunder Storm/ Wind" = "Flooding",
                  "Flooding/ Wind" = "Flooding",
                  "Drought" = "Drought/ Heat",
                  "Hurricane/Tropical Storm/ Severe Storm/Thunder Storm" = "Hurricane",
                  "Coastal/ Flooding" = "Coastal",
                  "Flooding/ Lightning" = "Flooding",
                  "Coastal/ Severe Storm/Thunder Storm/ Wind" = "Coastal",
                  "Coastal/ Severe Storm/Thunder Storm" = "Coastal",
                  "Coastal/ Flooding/ Severe Storm/Thunder Storm/ Wind" = "Coastal",
                  "Lightning/ Tornado/ Wind" = "Tornado",
                  "Flooding/ Lightning/ Wind" = "Flooding",
                  "Flooding/ Hail"= "Flooding",
                  "Hail/ Tornado" = "Tornado",
                  "Hail/ Severe Storm/Thunder Storm/ Wind/ Winter Weather" = "Severe Weather",
                  "Coastal/ Hurricane/Tropical Storm/ Severe Storm/Thunder Storm/ Wind" = "Hurricane",
                  "Flooding/ Hail/ Wind"= "Flooding",
                  "Fog" = "Fog",
                  "Severe Storm/Thunder Storm - Wind" = "Severe Weather")) %>%
  filter(Hazard.Event != "Fog")

summary(clusters)
```
  
_Identified Hazard Event based on the clustering_  
```{r, echo=FALSE}
(kable(unique(clusters$Hazard.Event), "pipe", col.names = "Hazard Events", align = "c"))
```
### Hazard Analysis
##### Frequency by hazard to determine the level of hazard
```{r}
frequency_hazard <- clusters %>% 
  group_by(clusters$Hazard.Event) %>% 
  summarise(events.pa = n(), prop_damage = sum(Property.Damage),
            damage_per_event = sum(Property.Damage)/n(), risk_level =
              ifelse(damage_per_event <= 1000000,"minor",
                     ifelse(damage_per_event<= 10000000,"medium","major")))

## find the mean of losses for each risk level
minor_mean <- frequency_hazard %>% 
    group_by(risk_level) %>% 
    filter(risk_level == "minor") %>% 
    summarise(dam = mean(damage_per_event)) #517881

medium_mean <- frequency_hazard %>% 
  group_by(risk_level) %>% 
  filter(risk_level == "medium") %>% 
  summarise(dam = mean(damage_per_event)) #4345546

major_mean <- frequency_hazard %>% 
  group_by(risk_level) %>% 
  filter(risk_level == "major") %>% 
  summarise(dam = mean(damage_per_event)) #134796018

## assign weighting for each risk
damage_table <- rbind(minor_mean, medium_mean, major_mean)
colnames(damage_table) <- c("Risk Level", "Average Damage")
kable(damage_table, align = "cr") %>%
  kable_styling(full_width = FALSE)

weighting_minor <- as.numeric(damage_table[1,2]/sum(damage_table[,2]))
weighting_medium <- as.numeric(damage_table[2,2]/sum(damage_table[,2]))
weighting_major <- as.numeric(damage_table[3,2]/sum(damage_table[,2]))
## check
sum(weighting_minor+weighting_medium+weighting_major)
```
##### Frequency by Region
```{r}
frequency_region <- clusters %>% 
  group_by(Region,Year) %>% 
  dplyr::summarise(tot_minor = sum(Hazard.Event == "Severe Weather"),
                   tot_medium = (sum(Hazard.Event == "Coastal")+
                                   sum( Hazard.Event == "Drought/ Heat")+
                                   sum(Hazard.Event == "Flooding")+
                                   sum(Hazard.Event == "Tornado")),
                   tot_major = (sum(Hazard.Event == "Wildfire")+
                                  sum( Hazard.Event == "Hurricane")),
                   tot_event = tot_minor + tot_medium + tot_major,
                   prop_damage = sum(Property.Damage), .groups='drop')

## quantify the region to low risk, med risk and high risk
# checking per region the no of minor, med and major risk and the prop damage
analyse_reg1 <- frequency_region %>% 
  filter(Region==1) %>% 
  summarise(Region = "Region 1", 
            minor = sum(tot_minor), medium = sum(tot_medium),
            major = sum(tot_major), sum_damage = sum(prop_damage))

analyse_reg2 <- frequency_region %>% 
  filter(Region==2) %>% 
  summarise(Region ="Region 2",
            minor = sum(tot_minor), medium = sum(tot_medium),
            major = sum(tot_major), sum_damage = sum(prop_damage))

analyse_reg3 <- frequency_region %>% 
  filter(Region==3) %>% 
  summarise(Region ="Region 3",
            minor = sum(tot_minor), medium = sum(tot_medium),
            major = sum(tot_major), sum_damage = sum(prop_damage))

analyse_reg4 <- frequency_region %>% 
  filter(Region==4) %>% 
  summarise(Region ="Region 4",
            minor = sum(tot_minor), medium = sum(tot_medium),
            major = sum(tot_major), sum_damage = sum(prop_damage))

analyse_reg5 <- frequency_region %>% 
  filter(Region==5) %>% 
  summarise(Region ="Region 5",
            minor = sum(tot_minor), medium = sum(tot_medium),
            major = sum(tot_major), sum_damage = sum(prop_damage))

analyse_reg6 <- frequency_region %>% 
  filter(Region==6) %>% 
  summarise(Region ="Region 6",
            minor = sum(tot_minor), medium = sum(tot_medium),
            major = sum(tot_major), sum_damage = sum(prop_damage))

region_analysis <- rbind(analyse_reg1,analyse_reg2,analyse_reg3,analyse_reg4,analyse_reg5,analyse_reg6)
colnames(region_analysis)[5] <- "Total Damage"
kable(region_analysis) %>% 
  kable_styling(full_width = F)

# find the mean and median for each classes of event per region
minor_med <- median(region_analysis$minor) #379
medium_med <- median(region_analysis$medium) #117.5
major_med <- median(region_analysis$major) #11

minor_mean <- mean(region_analysis$minor) #369.833
medium_mean <- mean(region_analysis$medium) #121
major_mean <- mean(region_analysis$major) #14.333

damage_r1 <- region_analysis %>% filter(Region == "Region 1") %>%
  summarise(damage = minor*weighting_minor + medium*weighting_medium +
              major*weighting_major)
damage_r2 <- region_analysis %>% filter(Region == "Region 2") %>%
  summarise(damage = minor*weighting_minor + medium*weighting_medium +
              major*weighting_major)
damage_r3 <- region_analysis %>% filter(Region == "Region 3") %>%
  summarise(damage = minor*weighting_minor + medium*weighting_medium +
              major*weighting_major)
damage_r4 <- region_analysis %>% filter(Region == "Region 4") %>%
  summarise(damage = minor*weighting_minor + medium*weighting_medium +
              major*weighting_major)
damage_r5 <- region_analysis %>% filter(Region == "Region 5") %>%
  summarise(damage = minor*weighting_minor + medium*weighting_medium +
              major*weighting_major)
damage_r6 <- region_analysis %>% filter(Region == "Region 6") %>%
  summarise(damage = minor*weighting_minor + medium*weighting_medium +
              major*weighting_major)

reg_damage_analysis <- rbind(damage_r1, damage_r2, damage_r3, damage_r4, damage_r5, damage_r6)

reg_damage_analysis <- tibble::rownames_to_column(reg_damage_analysis, "Region")
colnames(reg_damage_analysis)[2] <- "Adj. Freq"

kable(reg_damage_analysis, align = "cr", caption = "Weight Adjusted Hazard's Frequency") %>% 
  kable_styling(full_width = F)

quantile(reg_damage_analysis$`Adj. Freq`,c(.33, .67))
#     33%      67% 
# 14.74977 16.65021 

region_risk <- ifelse(reg_damage_analysis$`Adj. Freq` <=
                        quantile(reg_damage_analysis$`Adj. Freq`,c(.33)), "Low Risk",
                ifelse(reg_damage_analysis$`Adj. Freq` <=
                        quantile(reg_damage_analysis$`Adj. Freq`,c(.67)), "Medium Risk","High Risk"))

region_risk <- data.frame(region_risk)

region_risk <- tibble::rownames_to_column(region_risk, "Region")
colnames(region_risk)[2] <- "Risk Level"

kable(region_risk, align = "cl", caption = "Region Risk Level") %>%
  kable_styling(full_width = F)

```                     
  
### Census Data Analysis
```{r, message=FALSE}
# Extract the variables
pop_2021 <- census[1,]
pop_2020 <- census[2,]
gdp_2020 <- census[28,]
temp_housing_cost_wdis <- census[30,]
median_mthly_housing_cost<- census[9,]
person_per_hh <- census[19,]
no_hh <- census[18,]
housing_units <- census[6,]
owner_occupied_housing_units <- census[7,]
```

*Evaluating the property value*
```{r}

property.value <- census[-c(1:30), ] %>% 
# remove unwanted rows
  mutate(across(Region.1:Region.6, ~. *100))
  # convert from decimal to percentage

PVD_df <- data.frame(
  Region_1 = c(property.value[1,1], sum(property.value[c(2:4), 1]), sum(property.value[c(5:7), 1]), sum(property.value[c(8:10), 1]), sum(property.value[c(11:13), 1])),
  Region_2 = c(property.value[1,2], sum(property.value[c(2:4), 2]), sum(property.value[c(5:7), 2]), sum(property.value[c(8:10), 2]), sum(property.value[c(11:13), 2])),
  Region_3 = c(property.value[1,3], sum(property.value[c(2:4), 3]), sum(property.value[c(5:7), 3]), sum(property.value[c(8:10), 3]), sum(property.value[c(11:13), 3])), 
  Region_4 = c(property.value[1,4], sum(property.value[c(2:4), 4]), sum(property.value[c(5:7), 4]), sum(property.value[c(8:10), 4]), sum(property.value[c(11:13), 4])),
  Region_5 = c(property.value[1,5], sum(property.value[c(2:4), 5]), sum(property.value[c(5:7), 5]), sum(property.value[c(8:10), 5]), sum(property.value[c(11:13), 5])),
  Region_6 = c(property.value[1,6], sum(property.value[c(2:4), 6]), sum(property.value[c(5:7), 6]), sum(property.value[c(8:10), 6]), sum(property.value[c(11:13), 6])), 
  row.names = c("<50", "50-199", "200-399", "400-999", ">1000"))

PVD_df <- tibble::rownames_to_column(PVD_df, "PVD") # change format: rownames to column so ggplot2 can plot

PVD_final <- pivot_longer(PVD_df, cols=2:7, names_to = "Region", values_to = "Percent")
```
```{r, echo=FALSE}
kable(PVD_df, format = "pipe")
ggplot(PVD_final, 
       aes(x = factor(PVD, level = c("<50", "50-199","200-399",
                                     "400-999", ">1000")), 
           y = Percent, fill = Region)) +
    geom_bar(stat ="identity", 
             position = position_dodge(), 
             colour = "black") +
    scale_fill_brewer() +
    theme_minimal() +
    ggtitle("Property Value Distribution by Region") +
    xlab("Property Value (P1000)") +
    ylab("Percentage of Homes in Value Category")

pop_table <- t(rbind(pop_2021, gdp_2020))
colnames(pop_table) <- c("Population_2021", "GDP_2020( P1,000 )")
kable(pop_table) %>%
  kable_styling(full_width = F)
```

*Extra details*
```{r, warning=FALSE, message=FALSE}
# find out how many person live alone and with fam
(person_with_fam <- person_per_hh*no_hh)

(person_living_alone <- pop_2020-person_with_fam )

# find out no of houses for rent
(rent_house <- housing_units - owner_occupied_housing_units )

# no of person per house in the region
(no_person_per_house <- pop_2020/housing_units)

# check if there is enough no of accommodation for voluntary relocation
(person_per_hh)
# assume one house can have as much people as persons in a hh
# assume those living alone is renting

# no of available space for rent 
tot_rental <- person_per_hh*rent_house
tot_rental_occupied <- person_living_alone
tot_rental_available <- tot_rental - tot_rental_occupied

# population
pop_table <- t(rbind(pop_2020, gdp_2020, temp_housing_cost_wdis, median_mthly_housing_cost))
colnames(pop_table) <- c("Population_2020", "GDP_2020( P1,000 )", "Temp Housing Cost After Disaster", "Median Mthly Housing Cost (P pp per mth)" )


cens_df <- (rbind(pop_2020, person_with_fam, person_living_alone, rent_house, tot_rental_occupied, tot_rental_available))
rownames(cens_df) <- c("Population 2020", "Person with fam", "Person live alone", "No House for rent", "Rental Occupied", "Rental Available")
kable(cens_df, format = "pipe")
```

### Frequency and Severity Analysis
#### Frequency
```{r, warning=FALSE, message=FALSE}
# frequency by year

frequency <- hazards %>%
  group_by(Year) %>% 
  dplyr::summarise(events.pa = n())

#poisson
fit_poisson <- fitdistr(frequency$events.pa, "Poisson")

ks_poisson <- ks.test(unique(frequency$events.pa), "ppois", lambda = 49.704918)
ad_poisson <- ad.test(frequency$events.pa, "ppois", lambda = 49.704918)
cvm_poisson <- cvm.test(frequency$events.pa, "ppois", lambda = 49.704918)

#negative binomial
fit_nbin <- fitdistr(frequency$events.pa, "negative binomial")

ks_nbin <- ks.test(unique(frequency$events.pa), "pnbinom", size = 1.948557, mu = 49.704918)
ad_nbin <- ad.test(frequency$events.pa, "pnbinom", size = 1.948557, mu = 49.704918)
cvm_nbin <- cvm.test(frequency$events.pa, "pnbinom", size = 1.948557, mu = 49.704918)

# We find the parameters as follow
# Parameters
par_poi <- data.frame(fit_poisson$estimate, fit_poisson$sd)
par_poi <- t(par_poi)

par_nb <- data.frame(fit_nbin$estimate, fit_nbin$sd)
par_nb <- t(par_nb)

par_fr <- cbind(par_poi, par_nb)
rownames(par_fr) <- c("Estimate", "St. Dev")
kable(par_fr, format = "pipe") %>%
  kable_styling(full_width = F)

# p-value of tests
tests <- c("Kolmogorov-Smirnov", "Anderson-Darling", "Cramer-von Mises")

poi_pval <- c(ks_poisson$p.value, ad_poisson$p.value, cvm_poisson$p.value)
nb_pval <- c(ks_nbin$p.value, ad_nbin$p.value, cvm_nbin$p.value)
fr_pval <- data.frame(poi_pval, nb_pval)
rownames(fr_pval) <- tests
colnames(fr_pval) <- c("Poisson", "Neg. Binom")
# p-value statistics of the tests shows that there's not enough evidence to reject that the frequency follows negative binomial distribution
kable(fr_pval, format = "pipe") %>%
  kable_styling(full_width = F)
```
#### Severity
```{r, warning=FALSE, message=FALSE}
severity <- hazards %>% dplyr::select(Property.Damage)

ggplot(severity, aes(x = Property.Damage)) + geom_histogram(bins = 100) + xlim(c(0, 1000000)) # very skewed distribution

# First, fit a Gamma on severity
FG <- egamma(severity$Property.Damage, method = "mle")

ggplot(severity, aes(sample = Property.Damage)) +
    stat_qq(distribution = qgamma, dparams = c(shape = 1.001714e+00, rate = 1/6.534646e+06), colour = "#00BFC4", size = 1) +
    geom_abline(slope=1, intercept = 0) +
    theme_bw() +
    theme(axis.title = element_text(size = 13.5)) +
    ggtitle("Gamma") +
    xlab("Theoretical") +
    ylab("Sample")
# MLE gamma fit highly underestimates damages - try log of gamma

# Next, try LogGamma
sevlog <- severity %>% mutate(Property.Damage = log(Property.Damage))
FGL <- egamma(sevlog$Property.Damage, method = "mle")

ggplot(sevlog, aes(sample = Property.Damage)) +
    stat_qq(distribution = qgamma, dparams = c(shape = 14.8283973, rate = 1/0.7073224), colour = "#00BFC4", size = 1) +
    geom_abline(slope=1, intercept = 0) +
    theme_bw() +
    theme(axis.title = element_text(size = 13.5)) +
    ggtitle("Ln(Damages) ~ Gamma") +
    xlab("Theoretical") +
    ylab("Sample")

# much better fit! Now try LogNormal

FL <- fitdistr(severity$Property.Damage, "lognormal")

ggplot(severity, aes(sample = Property.Damage)) +
    stat_qq(distribution = qlnorm, dparams = c(meanlog = 10.48845700, sdlog = 2.61966147), colour = "#00BFC4", size = 1) +
    geom_abline(slope=1, intercept = 0) +
    theme_bw() +
    theme(axis.title = element_text(size = 13.5)) +
    ggtitle("Lognormal") +
    xlab("Theoretical") +
    ylab("Sample")

# LogNormal also systematically underestimates damages

# Now split by region (under LogGamma):
```
```{r, warning=FALSE, message=FALSE, echo=FALSE, fig.show="hold", out.width="50%"}
sev_r1 <- hazards  %>% 
  filter(Region == "1") %>% 
  dplyr::select(Property.Damage) %>% 
  mutate(Property.Damage = log(Property.Damage))  
sev_r2 <- hazards  %>% 
  filter(Region == "2") %>% 
  dplyr::select(Property.Damage) %>% 
  mutate(Property.Damage = log(Property.Damage))
sev_r3 <- hazards  %>% 
  filter(Region == "3") %>% 
  dplyr::select(Property.Damage) %>% 
  mutate(Property.Damage = log(Property.Damage))
sev_r4 <- hazards  %>% 
  filter(Region == "4") %>% 
  dplyr::select(Property.Damage) %>% 
  mutate(Property.Damage = log(Property.Damage))
sev_r5 <- hazards  %>% 
  filter(Region == "5") %>% 
  dplyr::select(Property.Damage) %>% 
  mutate(Property.Damage = log(Property.Damage))
sev_r6 <- hazards  %>% 
  filter(Region == "6") %>% 
  dplyr::select(Property.Damage) %>%
  mutate(Property.Damage = log(Property.Damage))

FG1 <- egamma(sev_r1$Property.Damage, method = "mle")
FG2 <- egamma(sev_r2$Property.Damage, method = "mle")
FG3 <- egamma(sev_r3$Property.Damage, method = "mle")
FG4 <- egamma(sev_r4$Property.Damage, method = "mle")
FG5 <- egamma(sev_r5$Property.Damage, method = "mle")
FG6 <- egamma(sev_r6$Property.Damage, method = "mle")


ggplot(sev_r1, aes(sample = Property.Damage)) +
    stat_qq(distribution = qgamma, dparams = c(shape = 13.9447973, scale = 0.7622203), colour = "#00BFC4", size = 1) +
    geom_abline(slope=1, intercept = 0) +
    theme_bw() +
    theme(axis.title = element_text(size = 13.5)) +
    ggtitle("Log Gamma R1") +
    xlab("Theoretical") +
    ylab("Sample")

ggplot(sev_r2, aes(sample = Property.Damage)) +
    stat_qq(distribution = qgamma, dparams = c(shape = 17.9265132, scale = 0.6116642), colour = "#00BFC4", size = 1) +
    geom_abline(slope=1, intercept = 0) +
    theme_bw() +
    theme(axis.title = element_text(size = 13.5)) +
    ggtitle("Log Gamma R2") +
    xlab("Theoretical") +
    ylab("Sample")

ggplot(sev_r3, aes(sample = Property.Damage)) +
    stat_qq(distribution = qgamma, dparams = c(shape = 14.2931748, scale = 0.7238527), colour = "#00BFC4", size = 1) +
    geom_abline(slope=1, intercept = 0) +
    theme_bw() +
    theme(axis.title = element_text(size = 13.5)) +
    ggtitle("Log Gamma R3") +
    xlab("Theoretical") +
    ylab("Sample")

ggplot(sev_r4, aes(sample = Property.Damage)) +
    stat_qq(distribution = qgamma, dparams = c(shape = 15.7694419, scale = 0.6494495), colour = "#00BFC4", size = 1) +
    geom_abline(slope=1, intercept = 0) +
    theme_bw() +
    theme(axis.title = element_text(size = 13.5)) +
    ggtitle("Log Gamma R4") +
    xlab("Theoretical") +
    ylab("Sample")

ggplot(sev_r5, aes(sample = Property.Damage)) +
    stat_qq(distribution = qgamma, dparams = c(shape = 15.0962915, scale = 0.6756838), colour = "#00BFC4", size = 1) +
    geom_abline(slope=1, intercept = 0) +
    theme_bw() +
    theme(axis.title = element_text(size = 13.5)) +
    ggtitle("Log Gamma R5") +
    xlab("Theoretical") +
    ylab("Sample")

ggplot(sev_r6, aes(sample = Property.Damage)) +
    stat_qq(distribution = qgamma, dparams = c(shape = 11.5229591, scale = 0.8736234), colour = "#00BFC4", size = 1) +
    geom_abline(slope=1, intercept = 0) +
    theme_bw() +
    theme(axis.title = element_text(size = 13.5)) +
    ggtitle("Log Gamma R6") +
    xlab("Theoretical") +
    ylab("Sample")
```
```{r, warning=F, message=F}
# Anderson-Darling Goodness of Fit test on each region above
```
```{r,warning=FALSE, message=FALSE, echo=FALSE}
ad1 <- ad.test(sev_r1$Property.Damage, "pgamma", shape = 13.9447973, scale = 0.7622203)
ad2 <- ad.test(sev_r2$Property.Damage, "pgamma", shape = 17.9265132, scale = 0.6116642)
ad3 <- ad.test(sev_r3$Property.Damage, "pgamma", shape = 14.2931748, scale = 0.7238527)
ad4 <- ad.test(sev_r4$Property.Damage, "pgamma", shape = 15.7694419, scale = 0.6494495)
ad5 <- ad.test(sev_r5$Property.Damage, "pgamma", shape = 15.0962915, scale = 0.6756838)
ad6 <- ad.test(sev_r6$Property.Damage, "pgamma", shape = 11.5229591, scale = 0.8736234)

# p-value of each region AD tests
reg_par <- data.frame(FG1$parameters, FG2$parameters, FG3$parameters, FG4$parameters, FG5$parameters, FG6$parameters)
colnames(reg_par) <- c(1:6)

kable(reg_par, align = "rrrrrr", caption = "Parameters") %>%
  kable_styling(full_width = F)

pval_reg <- c(ad1$p.value, ad2$p.value, ad3$p.value, ad4$p.value, ad5$p.value, ad6$p.value)
pval_reg <- data.frame(pval_reg)
pval_reg <- rownames_to_column(pval_reg)
colnames(pval_reg) <- c("Region","p-value")

kable(pval_reg, align = "cr", caption = "AD Test per Region") %>%
  kable_styling(full_width = F)
```
```{r} 
# not great, but good enough 
```
# 3. Monte Carlo Simulation
### Average Aggregate loss in n-years, using MLE Parameters
```{r, warning=F}
n_years <- 10 # feel free to adjust: e.g. if you want aggregate loss in 5 years, put n_years <- 5
n_iterations <- 100000 # number of Monte_Carlo simulations: also feel free to adjust.
size <- 1.948557
mu <- 49.704918
shapelog <- 14.829296
ratelog <- 1.413602

sev <- c()

for (i in 1:n_iterations) {
  
  for (i in 1:n_years) {
    freq_vec <- rnbinom(n_years, size = size, mu = mu)
    sev_obs <- sum(rlgamma(freq_vec[i], shapelog = shapelog, ratelog = ratelog))
  }
  
  sev <- append(sev, sev_obs)
  
}

#sanity check: mean aggregate loss in n years / cumulative historical property damages: should be about = n_years / 60
(mean(sev)/sum(hazards$Property.Damage) )
#I got 0.06579576. For n_years = 10, this should be about 0.1667
#Possible reason for small value: 
#the historical losses include some years where total losses are extreme, which isn't captured by just taking mean(sev)

sev_df <- data.frame(sev)
ggplot(sev_df, aes(x = sev)) + 
    geom_histogram(bins = 100) +
    xlim(c(0, 1000000000)) + ylim(c(0,15000)) +
    ggtitle("Aggregate Loss across Instances") +
    xlab("Aggregate Loss in N Years") +
    ylab("Sample")
```

